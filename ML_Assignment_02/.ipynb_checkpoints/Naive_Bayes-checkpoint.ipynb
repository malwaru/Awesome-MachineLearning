{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" >\n",
    "    <h1>Machine Learning: Assignment 2</h1>\n",
    "    <h2>This is a two week assignment</h2>\n",
    "    <h3>General Information:</h3>\n",
    "    <p>Feel free to add cells if required.<br> Feel free to write your own function block to reduce the redundancy.<br> Answers belong into the corresponding cells (below the question). <br><br> If you encounter empty cells underneath the answer that can not be edited, please ignore them, they are for testing purposes.<br><br>When editing an assignment there can be the case that there are variables in the kernel. To make sure your assignment works, please restart the kernel and run all cells before submitting (e.g. via <i>Kernel -> Restart & Run All</i>). We don't consider that respective solution if you make this mistake (no excuse).</p>\n",
    "    <br><br><b> Plot should have axis labels, grid, legend, title, atleast size 10X10 .Also give proper comments, function name, variable names to your coding, if you didn't follow the instructions there will be a reduction in the points.</b><br><br> \n",
    "     <br><br><b> Write sudo-code if you didn't get output or left out of time so that you will be awarded with atmost 50% of marks for that particular session.</b><br><br>\n",
    "    <h3>Submission:</h3>\n",
    "    <p>Use the following naming convention for your submissions: LA_FirstnameLastname_dateOfLecture, e.g LA_JohnDoe_YYMMDD\n",
    "     <br><br>Please submit your notebook via LEA. The assignment is due on <b>$1^{st}$ May, Saturday at 18:00.</b> </p>\n",
    "    <h3>Group Work:</h3>\n",
    "    <p>You are allowed to work in groups of up to two people. Please enter the UID (your username here) of each member of the group into the next cell. We apply plagiarism checking, so do not submit solutions from other people except your team members. If an assignment has a copied solution, the task will be graded with 0 points for all people with the same solution.</p>\n",
    "    <p><b>YOU SHOULD ONLY SUBMIT EXACTLY ONE PER GROUP</b></p>\n",
    "    <h3>Questions about the Assignment:</h3>\n",
    "    <p>If you have questions about the assignment please post them in the LEA forum before the deadline. Don't wait until the last day to post questions.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Group Work:\n",
    "Enter the UID (i.e. student2s) of each team member into the variables. \n",
    "If you work alone please leave the second variable empty, or extend the list if necessary.\n",
    "'''\n",
    "member1 = ''\n",
    "member2 = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Build a spam classifier using Naive Bayes[100 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#Headers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import sklearn\n",
    "#Include your other headers here\n",
    "\n",
    "from classifier import NaiveBayesClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Step 1:- Load your data[10 points]\n",
    "#### There are three datasets for training: TrainDataset1.csv, TrainDataset2.csv and TrainDataset3.txt. Each dataset contains short messages with the labels (ham or spam). Load the dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5560 entries in 'TrainDataset1.csv'.\n",
      "[{'type': 'type', 'text': 'text'}, {'type': 'ham', 'text': 'Hope you are having a good week. Just checking in'}, {'type': 'ham', 'text': 'K..give back my thanks.'}, {'type': 'ham', 'text': 'Am also doing in cbe only. But have to pay.'}, {'type': 'spam', 'text': 'complimentary 4 STAR Ibiza Holiday or £10,000 cash needs your URGENT collection. 09066364349 NOW from Landline not to lose out! Box434SK38WP150PPM18+'}, {'type': 'spam', 'text': 'okmail: Dear Dave this is your final notice to collect your 4* Tenerife Holiday or #5000 CASH award! Call 09061743806 from landline. TCs SAE Box326 CW25WX 150ppm'}, {'type': 'ham', 'text': 'Aiya we discuss later lar... Pick u up at 4 is it?'}, {'type': 'ham', 'text': 'Are you this much buzy'}, {'type': 'ham', 'text': 'Please ask mummy to call father'}, {'type': 'spam', 'text': 'Marvel Mobile Play the official Ultimate Spider-man game (£4.50) on ur mobile right now. Text SPIDER to 83338 for the game & we ll send u a FREE 8Ball wallpaper'}]\n",
      "[{'type': 'spam', 'text': 'U were outbid by simonwatson5120 on the Shinco DVD Plyr. 2 bid again, visit sms. ac/smsrewards 2 end bid notifications, reply END OUT'}, {'type': 'ham', 'text': 'Do you still have the grinder?'}, {'type': 'ham', 'text': 'No. Yes please. Been swimming?'}, {'type': 'ham', 'text': 'No de.am seeing in online shop so that i asked.'}, {'type': 'ham', 'text': 'Faith makes things possible,Hope makes things work,Love makes things beautiful,May you have all three this Christmas!Merry Christmas!'}, {'type': 'ham', 'text': 'Hey u still at the gym?'}, {'type': 'ham', 'text': 'Where is that one day training:-)'}, {'type': 'ham', 'text': 'Did I forget to tell you ? I want you , I need you, I crave you ... But most of all ... I love you my sweet Arabian steed ... Mmmmmm ... Yummy'}, {'type': 'ham', 'text': 'I dont thnk its a wrong calling between us'}, {'type': 'spam', 'text': 'December only! Had your mobile 11mths+? You are entitled to update to the latest colour camera mobile for Free! Call The Mobile Update Co FREE on 08002986906'}]\n"
     ]
    }
   ],
   "source": [
    "#Load your dataset in this cell\n",
    "# NOT USING PANDAS - i dont find it useful in this case! \n",
    "# Renamed function to be consisten with python naming conventions.\n",
    "def load_data():\n",
    "    \n",
    "    raw_data = []\n",
    "\n",
    "    with open(\"TrainDataset1.csv\", \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        # do not need the header\n",
    "        next(reader)\n",
    "\n",
    "        for row in reader:\n",
    "            raw_data.append({\"type\": row[0], \"text\": row[1]})\n",
    "        \n",
    "    size = len(raw_data)\n",
    "    print(f\"Found {size} entries in 'TrainDataset1.csv'.\")\n",
    "    print(raw_data[:10])\n",
    "    \n",
    "    raw_data_2 = []\n",
    "    \n",
    "    \n",
    "    with open(\"TrainDataset2.csv\", \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "                \n",
    "        # do not need the header\n",
    "        next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            raw_data_2.append({\"type\": row[0], \"text\": row[1]})\n",
    "\n",
    "    \n",
    "    print(raw_data_2[:10])\n",
    "#     collection_1 = np.loadtxt('TrainDataset1.csv')\n",
    "    \n",
    "    \n",
    "#     collection_2 = np.loadtxt('TrainDataset2.csv')\n",
    "#     collection_3 = np.loadtxt('TrainDataset3.txt')\n",
    "    \n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Step 2:- Preprocess the data[20 points]\n",
    "#### Analyse the data, for this you will need to process the text, namely remove punctuation and stopwords, and then create a list of clean text words (Research how to do this [Hint:- see how the texts are pre-processed in Natural Language Processing]) use any libraries that you feel comfortable. Now Combine them into one big data set for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#Pre-process the data\n",
    "def preProcessing():\n",
    "    #your code\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Step 3:- Visualise the data[20 points]\n",
    "#### Try to visualize and analyse the data such as before and after pre processing, number of ham/spam etc. Analyse as many verticals you can, feel free to use graphical libraries like seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#Visualise the data   \n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Step 4:- Build, train and validate the classifer, [20 points]\n",
    "\n",
    "### Training on supervised data (labelled data)\n",
    "\n",
    "#### Use the data in order to build your own Naive Bayes classifier (You can either use existing Naive Bayes from sklearn or build your own). Build the classifier, train it and then validate. Provide your result in confusion matrix (use heatmap from seaborn) along with the classification report from sklearn. Validation accuracy should be around 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Build, train and validate the classifier, \n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Step 5:- Test the classifier[10 points]\n",
    "\n",
    "### Supervised classification[5 points] \n",
    "\n",
    "#### Test your Classifier using  the SMSSpamCollection.txt dataset provide a heatmap and classification report. Test accuracy should be around 99%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Test the classifier\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Unsupervised classification[5 points] \n",
    "\n",
    "#### Test your Classifier using  the TestDataset.csv dataset. This dataset is not labelled so kindly predict the labels and visualise it[5 points]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Test the classifier\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Step 6:- Cheat the classifier[20 points]\n",
    "\n",
    "#### Try to cheat the classifier by adding \"good words\" to the end of test dataset(TestDataset.csv) e.g:- Oh! no share Market has fallen down by $100,000 due to Corona outbreak... try mixing up spam and ham words see how the classifier works. Output the results in a good format to validate your work[15 points]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Cheat the classifier\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Write your analysis of how you intended to cheat the classifier and how it performed in few words (provide your inference)[5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**Give your expalanation here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Help\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering\" target=\"_top\">Spam Filtering using Naive Bayes</a><br>\n",
    "<a href=\"https://seaborn.pydata.org/generated/seaborn.heatmap.html\" target=\"_top\">Seaborn Heatmap</a><br>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/naive_bayes.html\" target=\"_top\">Sklearn Naive Bayes</a><br>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html\" target=\"_top\">Sklearn Metrics</a><br>\n",
    "<a href=\"https://pandas.pydata.org/docs/getting_started/index.html#getting-started\" target=\"_top\">Intro to Pandas</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
